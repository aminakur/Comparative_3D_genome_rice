{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STREME motif identification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example script:<br>\n",
    "boundaries_unique_5kb_80_homer.bed --dna --oc streme_5kb_80% --n streme_background.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fasta file with background sequences (from entire genome)\n",
    "\n",
    "It is recommended to use at least two to three times as many background sequences as target sequences. I have 3636 boundaries at 2kb (80%), 1818 at 5kb (80%). I will use 12,000 background sequences for 2kb, 6000 for 5kb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing random 12/6,000 sequences to create background files:<br>\n",
    "streme_background_2kb.fa<br>\n",
    "streme_background_5kb.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "fasta_file = \"/scratch/ak8725/az_mrg/azucena.fna\"\n",
    "output_file = \"/scratch/ak8725/STREME/streme_background_5kb.fa\"\n",
    "num_fragments = 6000\n",
    "fragment_size = 6000\n",
    "\n",
    "# read in the input fasta file\n",
    "with open(fasta_file, \"r\") as f:\n",
    "    # read the first line (sequence ID)\n",
    "    seq_id = f.readline().strip().lstrip(\">\")\n",
    "    # read the remaining lines (sequence)\n",
    "    seq = \"\".join(line.strip() for line in f.readlines())\n",
    "\n",
    "seq_length = len(seq)\n",
    "\n",
    "fragments = []\n",
    "for i in range(num_fragments):\n",
    "    # generate a random start position within the sequence\n",
    "    start = random.randint(0, seq_length - fragment_size + 1)\n",
    "    end = start + fragment_size\n",
    "    fragment = seq[start:end]\n",
    "    fragment_id = f\"{seq_id}_fragment_{i+1}\"\n",
    "    fragments.append((fragment_id, fragment))\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for fragment_id, fragment_seq in fragments:\n",
    "        f.write(f\">{fragment_id}\\n{fragment_seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "fasta_file = \"/scratch/ak8725/az_mrg/azucena.fna\"\n",
    "output_file = \"/scratch/ak8725/STREME/streme_background_2kb.fa\"\n",
    "num_fragments = 12000\n",
    "fragment_size = 6000\n",
    "\n",
    "# read in the input fasta file\n",
    "with open(fasta_file, \"r\") as f:\n",
    "    # read the first line (sequence ID)\n",
    "    seq_id = f.readline().strip().lstrip(\">\")\n",
    "    # read the remaining lines (sequence)\n",
    "    seq = \"\".join(line.strip() for line in f.readlines())\n",
    "\n",
    "seq_length = len(seq)\n",
    "\n",
    "fragments = []\n",
    "for i in range(num_fragments):\n",
    "    # generate a random start position within the sequence\n",
    "    start = random.randint(0, seq_length - fragment_size + 1)\n",
    "    end = start + fragment_size\n",
    "    fragment = seq[start:end]\n",
    "    fragment_id = f\"{seq_id}_fragment_{i+1}\"\n",
    "    fragments.append((fragment_id, fragment))\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for fragment_id, fragment_seq in fragments:\n",
    "        f.write(f\">{fragment_id}\\n{fragment_seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created fasta files with unique boundaries\n",
    "boundaries_unique_5kb_80_homer.fna\n",
    "boundaries_unique_2kb_80_homer.fna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare genome file (changing chromosome names to chr01)\n",
    "# Open the input and output files\n",
    "with open('/scratch/ak8725/az_new/map_generation/azucena.fna', 'r') as fna_in, open('/scratch/ak8725/az_mrg/azucena_chr.fna', 'w') as fna_out:\n",
    "\n",
    "    # Iterate over the lines in the input file\n",
    "    for line in fna_in:\n",
    "        if line.startswith('>'):\n",
    "            # Modify the chromosome name in the header line\n",
    "            parts = line.strip().split()\n",
    "            chrom_name = parts[0].replace('Oryza sativa Japonica Group cultivar Azucena chromosome ', 'chr')\n",
    "            new_line = f'{chrom_name}\\n'\n",
    "            fna_out.write(new_line)\n",
    "        else:\n",
    "            # Copy the sequence lines unmodified\n",
    "            fna_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an .fna file with boundary sequences 5kb, 80%\n",
    "# Open the input and output files\n",
    "with open('/scratch/ak8725/az_mrg/azucena_chr.fna') as fna_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/boundaries_unique_5kb_80_homer.bed') as bed_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/boundaries_unique_5kb_80_homer.fna', 'w') as out_file:\n",
    "\n",
    "    # Process the genome in chunks\n",
    "    genome = {}\n",
    "    curr_seq = ''\n",
    "    for line in fna_file:\n",
    "        if line.startswith('>'):\n",
    "            if curr_seq:\n",
    "                genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "            curr_seq = line.strip()[1:]\n",
    "            genome[curr_seq] = []\n",
    "        else:\n",
    "            genome[curr_seq].append(line.strip())\n",
    "    genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "\n",
    "    # Process the bed file\n",
    "    for line in bed_file:\n",
    "        fields = line.strip().split('\\t')\n",
    "        seq_id = fields[0]\n",
    "        start = int(fields[1])\n",
    "        end = int(fields[2])\n",
    "        fragment_id = fields[3]\n",
    "        sequence = genome[seq_id][start:end]\n",
    "        header = f'>{seq_id}_{fragment_id}\\n'\n",
    "        out_file.write(header + sequence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an .fna file with conserved/nonconserved boundary sequences for sonia\n",
    "# Open the input and output files\n",
    "with open('/scratch/ak8725/NPB_new/map_generation/NPB.fna') as fna_file, \\\n",
    "     open('/scratch/ak8725/NPB_new/conservedBounds.bed') as bed_file, \\\n",
    "     open('/scratch/ak8725/NPB_new/conservedBounds.fna', 'w') as out_file:\n",
    "\n",
    "    # Process the genome in chunks\n",
    "    genome = {}\n",
    "    curr_seq = ''\n",
    "    for line in fna_file:\n",
    "        if line.startswith('>'):\n",
    "            if curr_seq:\n",
    "                genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "            curr_seq = line.strip()[1:]\n",
    "            genome[curr_seq] = []\n",
    "        else:\n",
    "            genome[curr_seq].append(line.strip())\n",
    "    genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "\n",
    "    # Process the bed file\n",
    "    for line in bed_file:\n",
    "        fields = line.strip().split('\\t')\n",
    "        seq_id = fields[0]\n",
    "        start = int(fields[1])\n",
    "        end = int(fields[2])\n",
    "        sequence = genome[seq_id][start:end]\n",
    "        header = f'>{seq_id}:{start}-{end}\\n'\n",
    "        out_file.write(header + sequence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">chr01_B1\n",
      "CCTTGATGACTCATCATACAAATCTCTGTCAGCACCCATGAAATATGCCTGCCCAAGCCGTACCAACTCCATTGATATATACAAAGAGATCGGAATGATGACCTGATATACAATCACCGCCATGAGGAATGTAATGAATATCTGCATCCCCATGCCATAGTAATTGTAGTTCTTCCCTGTCGTGTAATCCTTCTCCCTAAAGAACTGGGTGAATTCCAAATCCCCACGGTGATTCAGTATCCAAATCCCCGCGAGCACACTTGCGGTCGTGCACATCCCAATGAGCATAATGGACAGTATGACAGTCTCCCGGTTCAACTGTGTCTCCAACCGGCTCCGTTTCGACGGCGCCCCGGAGCTATTAAGCATGACCTTGGTCTCCTTTCCAGCATACACAACAACCCCTATCGCCCAGGTGGTATTCTTGAGCTCACATCCACGGAGCACAATGTTCGATGGCCCTAGCGAGACACGCTTGCCATCAATCTCCAAATTCGCCTGAAATCCATAGATGTTCCTGTTTGGCCGCTCACAATGAAGGACACCGCCGATTCCACCGTCCTGCGAGAACCTCAGTTGCGTCTCCTGCTTAGCATACCTCGTCTTGAGGTTGGTCTCCCCGTCAAGATTGACGGTCTGGACGTGCGCGACGCCGGAGGGGTCGCTGGTGGCGAGGAGCACCATGTCGGCAGGGAGCGTCTCGCTGGAGGCGACGCGGACGACGTCCCCGACGCGGATGTGCTTCCATTTCTTGGGCGCGAACTCccccgcggcgggcggcgccagGAGGACCCTGGCGAGGCGGTTGTTCTCCTGGCGgtcggagcggtggcggcggaggtccTCGTAGGCGTCCTTGACGGCGGTGACGAAGAGGACGAAGGCGAGCGGGAGCACGGAGGCGCCGCGGCCGAAGACGGCGACCTGGGGGAGCTGGTTGAGCACGGTGATGGCGAGGAAGTAGACGTACGACAGCCGCCGGAACTGCTCGAACAGGTTCCGCGGCAGGAACGTCAGCACCGAGTACTTCGCCGTCCGTACGCCGTTCCCGGcgaaccccgccgccgcctccgaagACGAGGGCTCCCCGACAACAACCGCGCGGgactcctcctcgccgcccccctcctcctccccccgctgCGACGCGGCCGACGACGGGTCGGGCTCCCGGCGGAAGGGGTCGGGCACCTCGAGGGAGAACGCGAGGCGGTCGGCTCGGAGGGGCGgctccggctgcggcggcgggagcagcgaTGACGCCGGCGGCTGCTGCGTCGGCCGCGGCGAGGCGTCGAGCAGCGGGCGCCCGGAAGCCATGGAGTCGGGGAAGCCGGAGCGAGCAGGGCTAGTGGGCCACCACCGGAGGcatggcggcgcgcggtggcgtCGGATTTGGgcgggaggtcgccggcgacggcgaggcagcTTGGAGAGGAAGAATCGAGAGGTTTCGGTTTGGAATTTtttggggaagaagaagaagaagcgaagcagaggagaggagaggagaggaaaggggTTAGGGGTTGGATTGTGATTTCTGGAGAGTACAGGGGGTTTACTGCGAAGTTTGGTCAGCCGATGGAAGACTACTGTCTTTTGAATTCGTGTGGCTTTTACGAACAACGGACCTGTTCACTTTatattcatttttaatttttccagaatttggTATTACCAAAAATATTTGGTAAGTTGCTAACGCTATCAAGGTTTTAAGGACTGGTtaaatatgatgatcaattctCTAGGTATGATAAATATTtagtaacaaactaaataatatcatatatttatcaattttacTAAATAATGGTATGGTATAAAATAACATGATTCTGAATAGGCCCTACCAATTACAATCGCCGTTCGAAAATTTAGGTCatgtttttttagagaaaagtaAGTGAATGAATTAATTTAGATATCTCAGGATGAAATTTTCATGTATTGGAAAACGGTGCCTTAGGAGGGAAGTAGTAGTAAACGGAATTATT\n",
      ">chr01_B2\n"
     ]
    }
   ],
   "source": [
    "!head -3 /scratch/ak8725/az_mrg/boundaries_unique_2kb_80_homer.fna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an .fna file with boundary sequences 2kb, 80%\n",
    "# Open the input and output files\n",
    "with open('/scratch/ak8725/az_mrg/azucena_chr.fna') as fna_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/boundaries_unique_2kb_80_homer.bed') as bed_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/boundaries_unique_2kb_80_homer.fna', 'w') as out_file:\n",
    "\n",
    "    # Process the genome in chunks\n",
    "    genome = {}\n",
    "    curr_seq = ''\n",
    "    for line in fna_file:\n",
    "        if line.startswith('>'):\n",
    "            if curr_seq:\n",
    "                genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "            curr_seq = line.strip()[1:]\n",
    "            genome[curr_seq] = []\n",
    "        else:\n",
    "            genome[curr_seq].append(line.strip())\n",
    "    genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "\n",
    "    # Process the bed file\n",
    "    for line in bed_file:\n",
    "        fields = line.strip().split('\\t')\n",
    "        seq_id = fields[0]\n",
    "        start = int(fields[1])\n",
    "        end = int(fields[2])\n",
    "        fragment_id = fields[3]\n",
    "        sequence = genome[seq_id][start:end]\n",
    "        header = f'>{seq_id}_{fragment_id}\\n'\n",
    "        out_file.write(header + sequence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then run /scratch/ak8725/STREME/streme.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streme --oc streme_5kb_80% --n streme_background_5kb.fa --p /scratch/ak8725/az_mrg/boundaries_unique_5kb_80_homer.fna \n",
    "streme --oc streme_2kb_80% --n streme_background_2kb.fa --p /scratch/ak8725/az_mrg/boundaries_unique_2kb_80_homer.fna "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiCExplorer boundaries at different resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create .fna with 1kb boundary sequences\n",
    "# Open the input and output files\n",
    "with open('/scratch/ak8725/az_mrg/azucena_chr.fna') as fna_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/hicFindTADs/hicFindTADs2_out/az_1kb_boundaries.bed') as bed_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/hicexp_1kb_homer.fna', 'w') as out_file:\n",
    "\n",
    "    # Process the genome in chunks\n",
    "    genome = {}\n",
    "    curr_seq = ''\n",
    "    for line in fna_file:\n",
    "        if line.startswith('>'):\n",
    "            if curr_seq:\n",
    "                genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "            curr_seq = line.strip()[1:]\n",
    "            genome[curr_seq] = []\n",
    "        else:\n",
    "            genome[curr_seq].append(line.strip())\n",
    "    genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "\n",
    "    # Process the bed file\n",
    "    for line in bed_file:\n",
    "        fields = line.strip().split('\\t')\n",
    "        seq_id = fields[0]\n",
    "        start = int(fields[1])\n",
    "        end = int(fields[2])\n",
    "        fragment_id = fields[3]\n",
    "        sequence = genome[seq_id][start:end]\n",
    "        header = f'>{seq_id}_{fragment_id}\\n'\n",
    "        out_file.write(header + sequence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create .fna with 2kb boundary sequences\n",
    "#create .fna with 1kb boundary sequences\n",
    "# Open the input and output files\n",
    "with open('/scratch/ak8725/az_mrg/azucena_chr.fna') as fna_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/hicFindTADs/hicFindTADs1_out/az_2kb_boundaries.bed') as bed_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/hicexp_2kb_homer.fna', 'w') as out_file:\n",
    "\n",
    "    # Process the genome in chunks\n",
    "    genome = {}\n",
    "    curr_seq = ''\n",
    "    for line in fna_file:\n",
    "        if line.startswith('>'):\n",
    "            if curr_seq:\n",
    "                genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "            curr_seq = line.strip()[1:]\n",
    "            genome[curr_seq] = []\n",
    "        else:\n",
    "            genome[curr_seq].append(line.strip())\n",
    "    genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "\n",
    "    # Process the bed file\n",
    "    for line in bed_file:\n",
    "        fields = line.strip().split('\\t')\n",
    "        seq_id = fields[0]\n",
    "        start = int(fields[1])\n",
    "        end = int(fields[2])\n",
    "        fragment_id = fields[3]\n",
    "        sequence = genome[seq_id][start:end]\n",
    "        header = f'>{seq_id}_{fragment_id}\\n'\n",
    "        out_file.write(header + sequence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create .fna with 5kb boundary sequences\n",
    "#create .fna with 1kb boundary sequences\n",
    "# Open the input and output files\n",
    "with open('/scratch/ak8725/az_mrg/azucena_chr.fna') as fna_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/hicFindTADs/hicFindTADs13_out/az_5kb_boundaries.bed') as bed_file, \\\n",
    "     open('/scratch/ak8725/az_mrg/hicexp_5kb_homer.fna', 'w') as out_file:\n",
    "\n",
    "    # Process the genome in chunks\n",
    "    genome = {}\n",
    "    curr_seq = ''\n",
    "    for line in fna_file:\n",
    "        if line.startswith('>'):\n",
    "            if curr_seq:\n",
    "                genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "            curr_seq = line.strip()[1:]\n",
    "            genome[curr_seq] = []\n",
    "        else:\n",
    "            genome[curr_seq].append(line.strip())\n",
    "    genome[curr_seq] = ''.join(genome[curr_seq])\n",
    "\n",
    "    # Process the bed file\n",
    "    for line in bed_file:\n",
    "        fields = line.strip().split('\\t')\n",
    "        seq_id = fields[0]\n",
    "        start = int(fields[1])\n",
    "        end = int(fields[2])\n",
    "        fragment_id = fields[3]\n",
    "        sequence = genome[seq_id][start:end]\n",
    "        header = f'>{seq_id}_{fragment_id}\\n'\n",
    "        out_file.write(header + sequence + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input files with boundary sequences:<br>\n",
    "    /scratch/ak8725/az_mrg/hicexp_1kb_boundaries.fna<br>\n",
    "    /scratch/ak8725/az_mrg/hicexp_2kb_boundaries.fna<br>\n",
    "    /scratch/ak8725/az_mrg/hicexp_5kb_boundaries.fna<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating background sequences. I will use 20,000 seqs for background. Seq length = 6000\n",
    "\n",
    "import random\n",
    "\n",
    "fasta_file = \"/scratch/ak8725/az_mrg/azucena.fna\"\n",
    "output_file = \"/scratch/ak8725/az_mrg/STREME/streme_background_20k.fa\"\n",
    "num_fragments = 20000\n",
    "fragment_size = 6000\n",
    "\n",
    "# read in the input fasta file\n",
    "with open(fasta_file, \"r\") as f:\n",
    "    # read the first line (sequence ID)\n",
    "    seq_id = f.readline().strip().lstrip(\">\")\n",
    "    # read the remaining lines (sequence)\n",
    "    seq = \"\".join(line.strip() for line in f.readlines())\n",
    "\n",
    "seq_length = len(seq)\n",
    "\n",
    "fragments = []\n",
    "for i in range(num_fragments):\n",
    "    # generate a random start position within the sequence\n",
    "    start = random.randint(0, seq_length - fragment_size + 1)\n",
    "    end = start + fragment_size\n",
    "    fragment = seq[start:end]\n",
    "    fragment_id = f\"{seq_id}_fragment_{i+1}\"\n",
    "    fragments.append((fragment_id, fragment))\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for fragment_id, fragment_seq in fragments:\n",
    "        f.write(f\">{fragment_id}\\n{fragment_seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating background sequences. I will use 12,000 seqs for background for 5kb query seqs. Seq length = 6000\n",
    "\n",
    "import random\n",
    "\n",
    "fasta_file = \"/scratch/ak8725/az_mrg/azucena.fna\"\n",
    "output_file = \"/scratch/ak8725/az_mrg/STREME/streme_background_12k.fa\"\n",
    "num_fragments = 12000\n",
    "fragment_size = 6000\n",
    "\n",
    "# read in the input fasta file\n",
    "with open(fasta_file, \"r\") as f:\n",
    "    # read the first line (sequence ID)\n",
    "    seq_id = f.readline().strip().lstrip(\">\")\n",
    "    # read the remaining lines (sequence)\n",
    "    seq = \"\".join(line.strip() for line in f.readlines())\n",
    "\n",
    "seq_length = len(seq)\n",
    "\n",
    "fragments = []\n",
    "for i in range(num_fragments):\n",
    "    # generate a random start position within the sequence\n",
    "    start = random.randint(0, seq_length - fragment_size + 1)\n",
    "    end = start + fragment_size\n",
    "    fragment = seq[start:end]\n",
    "    fragment_id = f\"{seq_id}_fragment_{i+1}\"\n",
    "    fragments.append((fragment_id, fragment))\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for fragment_id, fragment_seq in fragments:\n",
    "        f.write(f\">{fragment_id}\\n{fragment_seq}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
